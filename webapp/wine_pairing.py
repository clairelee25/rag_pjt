from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_core.runnables import RunnableLambda
from langchain_core.messages import HumanMessage, SystemMessage

from dotenv import load_dotenv
import os

load_dotenv(override=True, dotenv_path="../.env")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME")
PINECONE_NAMESPACE = os.getenv("PINECONE_NAMESPACE")

embedding = OpenAIEmbeddings(
     model = OPENAI_EMBEDDING_MODEL
 )

# LLMì„ í†µí•œ ìš”ë¦¬ ì •ë³´ ì„¤ëª…
# 1. í•¨ìˆ˜ ì •ì˜ : ì´ë¯¸ì§€ -> ìš”ë¦¬ëª…, í’ë¯¸ ì„¤ëª… ì¶œë ¥
def describe_dish_flavor(query):
    """
    query = {
        "image_base64": "..."
    }
    """

    messages = [
        SystemMessage(content="""
            You are a highly skilled culinary expert.
            Identify the dish and summarize its flavor profile in one concise English sentence.
            """),
        HumanMessage(
            content=[
                {"type": "text", "text": "Analyze the dish shown in the image."},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{query['image_base64']}"
                    }
                }
            ]
        )
    ]

    llm = ChatOpenAI(
        model='gpt-4o-mini',
        temperature=0.1,
        api_key=OPENAI_API_KEY
    )

    response = llm.invoke(messages)

    return response.content

# 2. í•¨ìˆ˜ ì •ì˜ : ìš”ë¦¬ ì„¤ëª… -> ìš”ë¦¬ ì„¤ëª…, ì™€ì¸ ì¶”ì²œ (Top-5)
def search_wines(query):
    embedding = OpenAIEmbeddings(
         model = OPENAI_EMBEDDING_MODEL
    )
    
    # ë²¡í„° dbì—ì„œ ìœ ì‚¬ë„ê³„ì‚°, top-5 ê²€ìƒ‰
    # ë²¡í„° db ê°ì²´ ìƒì„±
    vector_db = PineconeVectorStore(
        embedding = embedding,  # ì§ˆë¬¸ì— ëŒ€í•œ ì„ë² ë”© ë²¡í„°ê°€ ìƒì„±ë¨
        index_name = PINECONE_INDEX_NAME ,
        namespace = PINECONE_NAMESPACE
    )
    # ë²¡í„° dbì—ì„œ ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ, top-5 ê²€ìƒ‰í•˜ê¸°
    results = vector_db.similarity_search(query, k=5)  # top-5 ê²€ìƒ‰

    context = "\n".join([doc.page_content for doc in results])

    # í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•œ ìª½ìœ¼ë¡œ query, top-5ì˜ ê²€ìƒ‰ ê²°ê³¼ì— í•„í„°ë§í•œ ê²°ê³¼ë¥¼ ë¦¬í„´í•¨
    return {
        "query" : query,
        "wine_reviews" : context
    }

# 3. í•¨ìˆ˜ ì •ì˜ : ìš”ë¦¬ì„¤ëª…, top-5ì˜ context ì…ë ¥ ë°›ê³  -> ìš”ë¦¬ì— ì–´ìš¸ë¦¬ëŠ” ì™€ì¸ ì¶”ì²œ 
def recommand(query):
    prompt = ChatPromptTemplate([
        ("system", """
    ğŸ· Wine Sommelier â€“ System Prompt (Short / Optimized)
    You are a professional wine sommelier specialized in food and wine pairing.

    When responding, you:
    - Analyze food characteristics (ingredients, cooking method, sauce, flavor intensity)
    - Consider wine structure (acidity, tannin, sweetness, body, alcohol)
    - Apply pairing logic (balance, contrast, complement, intensity matching)

    You always:
    - Explain why a pairing works
    - Adapt recommendations to the customerâ€™s taste, budget, and occasion
    - Use clear, accessible language and avoid unnecessary jargon

    Your goal:
    Recommend wine pairings that create harmony between food and wine and maximize the customerâ€™s enjoyment.
        """),
        ("human", """ ì•„ë˜ ì™€ì¸ë¦¬ë·° ë‚´ìš©ì—ì„œë§Œ ì¶”ì²œì„ í•´ì¤˜
        ìš”ë¦¬ ì„¤ëª… : {query}
        ì™€ì¸ ë¦¬ë·° : {wine_reviews}
        
        ë‹µë³€ì€ jsonìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µí•´ ì£¼ì„¸ìš”.
        wine recommandation: 
        recommandation reason:
        """)
    ])

    llm = ChatOpenAI(
        model='gpt-4o-mini',
        temperature=0.1,
        api_key=OPENAI_API_KEY
    )

    # str íŒŒì„œ
    # output_parser = StrOutputParser()

    # json íŒŒì„œë¡œ ë³€ê²½
    output_parser = JsonOutputParser()

    # pipeline : ë°ì´í„°ì˜ íë¦„
    chain = prompt | llm | output_parser

    return chain.invoke(query)

# í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ëŠ” ì½”ë“œ
def wine_pair_main(image_base64: str):
    # RunnableLambda ê°ì²´ ìƒì„±(ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì—°ê²°ì„ ìœ„í•´)
    r1 = RunnableLambda(describe_dish_flavor)
    r2 = RunnableLambda(search_wines)
    r3 = RunnableLambda(recommand)

    # chainìœ¼ë¡œ ì—°ê²°í•˜ê¸°
    chain = r1 | r2 | r3

    # RunnableLambdaë¥¼ í†µí•œ í•¨ìˆ˜ ì‹¤í–‰
    
    res = chain.invoke({
        "image_base64": image_base64
    })
    return res

# ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    import base64
    print(__name__)
    print("-"*30)
    image_path = "../images/eye_catch_sushi.jpg"

    with open(image_path, "rb") as f:
        image_bytes = f.read()
    image_base64 = base64.b64encode(image_bytes).decode("utf-8")

    # img_url = "https://thumbnail.coupangcdn.com/thumbnails/remote/492x492ex/image/vendor_inventory/9d0d/fd3f0d77757f64b2eba0905dcdd85051932ec1ab5e6afc0c3246f403fabc.jpg"
    result = wine_pair_main(image_base64)
    print(result)

